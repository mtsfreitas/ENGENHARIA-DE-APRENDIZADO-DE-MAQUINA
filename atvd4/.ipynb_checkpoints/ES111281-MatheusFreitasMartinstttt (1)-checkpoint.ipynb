{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf63b525",
   "metadata": {},
   "source": [
    "# Atividade 4\n",
    "## Crie um modelo de classificação para detectar mensagems Spam\n",
    "\n",
    "* **Nome:** Matheus Freitas Martins\n",
    "* **Matrícula:** ES111281\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73711b69",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2689869858.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install -U ydata-profiling\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install -U ydata-profiling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from ydata_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ecff48",
   "metadata": {},
   "source": [
    "# 1. Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam-datasset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c62aa9",
   "metadata": {},
   "source": [
    "## 1.1 Entendendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be05d5",
   "metadata": {},
   "source": [
    "### 1.1.1 Gerando relatório detalhado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data, title=\"Spam Data Profiling Report\", explorative=True)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"spam_data_profiling_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf703f0",
   "metadata": {},
   "source": [
    "### 1.1.2 Observando frequência de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ce1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_word_frequencies(messages, title):\n",
    "    text = ' '.join(messages)\n",
    "    wordcloud = WordCloud(width=800, height=800, background_color='white', stopwords=None, max_words=100).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(3, 3), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "spam_messages = data[data['Category'] == 'spam']['Message']\n",
    "ham_messages = data[data['Category'] == 'ham']['Message']\n",
    "\n",
    "visualize_word_frequencies(spam_messages, 'Frequência de Palavras em Mensagens de Spam')\n",
    "visualize_word_frequencies(ham_messages, 'Frequência de Palavras em Mensagens Não Spam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd431ef0",
   "metadata": {},
   "source": [
    "## 1.2 Fazendo o pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30e98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.copy()\n",
    "# Removendo as linhas duplicadas do conjunto de dados.\n",
    "data = data.drop_duplicates()\n",
    "# Mapeando as categorias (ham e spam) para valores numéricos (0 e 1).\n",
    "data['Category'] = data['Category'].replace({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40d5b0",
   "metadata": {},
   "source": [
    "# 2. Criando atributos relevantes a partir do texto da mensagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01468b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o stemming para reduzir as palavras ao seu radical.\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "# Removendo palavras irrelevantes (stopwords).\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Função que tokeniza a mensagem, aplica o stemming e remove as stopwords e palavras não alfabéticas. \n",
    "# Retorna a mensagem pré-processada como uma string.\n",
    "def preprocess(message):\n",
    "    words = nltk.word_tokenize(message)\n",
    "    words = [stemmer.stem(word.lower()) for word in words if word.lower() not in stop_words and word.isalpha()]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['Message'] = data['Message'].apply(preprocess)\n",
    "\n",
    "# Balanceamento de dados\n",
    "spam = data[data['Category'] == 1]\n",
    "ham = data[data['Category'] == 0]\n",
    "\n",
    "\n",
    "# Aplicando a técnica de reamostragem (upsampling) no conjunto de spam para igualar a quantidade de exemplos de cada classe.\n",
    "spam_upsampled = resample(spam, replace=True, n_samples=len(ham), random_state=42)\n",
    "\n",
    "# Concatena os subconjuntos de ham e spam_upsampled para criar um conjunto de dados balanceado.\n",
    "data_balanced = pd.concat([ham, spam_upsampled])\n",
    "\n",
    "# Embaralhando aleatoriamente as linhas do DataFrame balanced_data e reinicializando o índice das linhas para garantir que os exemplos de treinamento e teste sejam selecionados aleatoriamente e que a ordem dos exemplos não afete o desempenho do modelo.\n",
    "data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a1d9d",
   "metadata": {},
   "source": [
    "# 3. Dividindo os dados em conjuntos de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% dos dados para treinamento e 30% para teste.\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_balanced['Message'], data_balanced['Category'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551a454",
   "metadata": {},
   "source": [
    "# 4. Treinando o modelo de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um objeto Pipeline que combina três etapas para processamento e classificação de texto:\n",
    "\n",
    "# Vetorização de contagem de palavras. Gera uma matriz esparsa onde cada linha representa uma mensagem e cada coluna representa um termo (ou token) único no conjunto de dados. \n",
    "# Transformação TF-IDF (Term Frequency-Inverse Document Frequency). Podenra a importância das palavras no conjunto de dados com base em suas frequências nas mensagens.\n",
    "# Aplicação do classificador Multinomial Naive Bayes. Utiliza frequências das palavras e probabilidades de classes para categorizar as mensagens.\n",
    "\n",
    "# O primeiro passo é converter o texto bruto em um vetor de contagens de termos.\n",
    "# O segundo passo consiste em obter o vetor de contagens de termos, que irá ponderar a importância das palavras usando a métrica TF-IDF\n",
    "# Por fim, depois de ter a matriz TF-IDF, pode-se aplicar o classificador Multinomial Naive Bayes para treinar e fazer previsões.\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0945ff9d",
   "metadata": {},
   "source": [
    "# 5. Avaliando o desempenho do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['ham', 'spam'], yticklabels=['ham', 'spam'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda304d",
   "metadata": {},
   "source": [
    "## Discussão dos resultados "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f6fff5",
   "metadata": {},
   "source": [
    "Usando upsampling:\n",
    "\n",
    "* F1-score (classe 0): 0.97\n",
    "* F1-score (classe 1): 0.97\n",
    "\n",
    "Usando downsampling:\n",
    "\n",
    "* F1-score (classe 0): 0.91\n",
    "* F1-score (classe 1): 0.92\n",
    "\n",
    "Neste caso, o modelo utilizando upsampling apresenta um F1-score mais alto para ambas as classes (0.97). Portanto, com base nos resultados fornecidos, o modelo utilizando upsampling é a melhor opção para equilibrar a detecção correta de ambas as classes, pois um F1-score mais alto indica um melhor equilíbrio entre precisão e recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d09d64",
   "metadata": {},
   "source": [
    "## Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b63c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acurácia: \", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b3a20",
   "metadata": {},
   "source": [
    "# Analisando se ocorreu overfiting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234bc3d",
   "metadata": {},
   "source": [
    "## cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb3094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule a acurácia usando validação cruzada com 5 folds\n",
    "# folds =  divide os dados de treinamento em k-folds (subconjuntos) e treina o modelo em cada um desses subconjuntos, enquanto usa o restante dos dados como conjunto de validação.\n",
    "# Divide o conjunto de treinamento em vários subconjuntos, treina e avalia o modelo várias vezes, usando um subconjunto diferente como conjunto de validação a cada vez.\n",
    "scores = cross_val_score(model, X_train, y_train, cv=15, scoring='accuracy')\n",
    "\n",
    "# Imprima os resultados\n",
    "print(f\"Acurácia média: {scores.mean():.2f}\")\n",
    "print(f\"Desvio padrão: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac5e15",
   "metadata": {},
   "source": [
    "De acordo com os resultados acima, é possível notar que o bom desempenho do modelo, pois conseguiu obter a acurácia média alta. Além disso, o desvio padrão baixo indica que os resultados são consistentes e que o modelo está generalizando bem para novos dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4360f28d",
   "metadata": {},
   "source": [
    "## Desempenho no conjunto de treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62948150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faça previsões para os conjuntos de treinamento e teste\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calcule a acurácia para os conjuntos de treinamento e teste\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Acurácia no conjunto de treinamento: {train_accuracy:.2f}\")\n",
    "print(f\"Acurácia no conjunto de teste: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651cd84",
   "metadata": {},
   "source": [
    "Observando os resultados acima, nota-se que a diferença na acurácia do conjunto de treinamento para a acurácia do conjunto de teste é muito pequena, portanto indica que o modelo está generalizando bem para os dados não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b531b",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma nova mensagem para teste\n",
    "mensagens_de_teste = [\n",
    "    \"Congratulations, you won the prize.\",\n",
    "    \"You have a meeting scheduled at 2 pm tomorrow.\",\n",
    "    \"Email urgent\", \n",
    "    \"Can you confirm by tomorrow?\",\n",
    "]\n",
    "\n",
    "# Faça a previsão usando o pipeline\n",
    "previsao_de_categorias = model.predict(mensagens_de_teste)\n",
    "\n",
    "# Verifique as categorias previstas\n",
    "for i, previsao in enumerate(previsao_de_categorias):\n",
    "    if previsao == 1:\n",
    "        print(f\"Mensagem {i + 1}: Esta mensagem é spam.\")\n",
    "    else:\n",
    "        print(f\"Mensagem {i + 1}: Esta mensagem é ham.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
